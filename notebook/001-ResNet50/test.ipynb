{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "#pyroch_lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "#huggingface\n",
    "from datasets import load_dataset\n",
    "\n",
    "pl.seed_everything(42)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのロード\n",
    "dataset = load_dataset(\"1aurent/PatchCamelyon\")\n",
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 1️⃣ データセット定義 ======\n",
    "class PatchCamelyonDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.70075713, 0.5383597, 0.69162006], std=[0.23497961, 0.27741011, 0.21289514]),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # 画像だけにtransformを適用する関数を定義\n",
    "        def transform_fn(examples):\n",
    "            examples[\"image\"] = [self.transform(img) for img in examples[\"image\"]]\n",
    "            examples[\"label\"] = [int(label) for label in examples[\"label\"]]\n",
    "            return examples\n",
    "        \n",
    "        self.train_dataset = self.dataset['train'].with_transform(transform_fn)\n",
    "        self.val_dataset = self.dataset['valid'].with_transform(transform_fn)\n",
    "        self.test_dataset = self.dataset['test'].with_transform(transform_fn)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=6)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 2️⃣ モデル定義 ======\n",
    "class ResNet50LitModel(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"label\"]\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (preds.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"label\"]\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (preds.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"label\"]\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (preds.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x = batch[\"image\"]\n",
    "        preds = self(x)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 3️⃣ 実行部分 ======\n",
    "\n",
    "# データとモデル\n",
    "data_module = PatchCamelyonDataModule(batch_size=256, dataset=dataset)\n",
    "data_module.setup(\"test\")  # testデータをセットアップ\n",
    "\n",
    "# 最良のckptパスを取得\n",
    "best_model_path = \"lightning_logs/resnet50/version_8/checkpoints/resnet50-epoch=00-val_acc=0.84.ckpt\"\n",
    "\n",
    "# モデルを復元\n",
    "model = ResNet50LitModel.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# テスト実行\n",
    "trainer = pl.Trainer(accelerator=\"auto\", devices=1)\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルから予測を得る\n",
    "preds = trainer.predict(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "n_samples = 20  # サンプリング数\n",
    "\n",
    "test_dataset = data_module.test_dataloader().dataset\n",
    "\n",
    "# ====== ランダムに20個サンプリング ======\n",
    "indices = random.sample(range(len(test_dataset)), n_samples)\n",
    "subset = Subset(test_dataset, indices)\n",
    "subset_loader = DataLoader(subset, batch_size=n_samples, shuffle=False, num_workers=6)\n",
    "\n",
    "# # ====== 予測を実行 ======\n",
    "preds = trainer.predict(model, dataloaders=subset_loader)\n",
    "pred_labels = preds[0].argmax(dim=1).cpu()\n",
    "\n",
    "# ===== 正規化を元に戻す関数 =====\n",
    "def denormalize(img):\n",
    "    mean = torch.tensor([0.70075713, 0.5383597, 0.69162006])\n",
    "    std = torch.tensor([0.23497961, 0.27741011, 0.21289514])\n",
    "    return (img * std + mean).clamp(0, 1)  # 0〜1にクリップ\n",
    "\n",
    "# クラス名\n",
    "classes = [\"Non-tumor\", \"Tumor\"]\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(n_samples):\n",
    "    image = subset[i][\"image\"]\n",
    "    label = subset[i][\"label\"]\n",
    "    pred_label = pred_labels[i]\n",
    "    img = denormalize(image.permute(1, 2, 0))\n",
    "    plt.subplot(2, n_samples // 2, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\n",
    "        f\"GT: {classes[label]}\\nPred: {classes[pred_label]}\",\n",
    "        color=(\"green\" if label == pred_label else \"red\")\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad-CAMの導入\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "# Grad-CAMのセットアップ\n",
    "target_layers = [model.model.layer4[-1]]\n",
    "cam = GradCAM(model=model.model, target_layers=target_layers)\n",
    "# 可視化\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(n_samples):\n",
    "    image = subset[i][\"image\"]\n",
    "    label = subset[i][\"label\"]\n",
    "    pred_label = pred_labels[i]\n",
    "    targets = [ClassifierOutputTarget(pred_label)]\n",
    "    img = denormalize(image.permute(1, 2, 0)).cpu().numpy()\n",
    "    input_tensor = image.unsqueeze(0).to(device)\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "    plt.subplot(2, n_samples // 2, i + 1)\n",
    "    plt.imshow(cam_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\n",
    "        f\"GT: {classes[label]}\\nPred: {classes[pred_label]}\",\n",
    "        color=(\"green\" if label == pred_label else \"red\")\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "i=0\n",
    "image = subset[i][\"image\"]\n",
    "label = subset[i][\"label\"]\n",
    "pred_label = pred_labels[i]\n",
    "targets = [ClassifierOutputTarget(pred_label)]\n",
    "img = denormalize(image.permute(1, 2, 0)).cpu().numpy()\n",
    "input_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "# You can also get the model outputs without having to redo inference\n",
    "model_outputs = cam.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch-camelyon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
